---
layout: project_page
permalink: /

title: "Scaling Robot Policy Learning via Zero-Shot Labeling with Foundation Models"
authors: Anonymous Author(s)
affiliations: Affiliation
paper: https://openreview.net/forum?id=EdVNB2kHv1
# video:
# code:
# data:
---


---

<html data-theme="light">

</html>

<link rel="stylesheet" href="./static/css/bulma.min.css">

<div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
        <h2>Abstract</h2>
        <div class="content has-text-justified">
            A central challenge towards developing robots that can relate human language to their perception and actions
            is the scarcity of natural language annotations in diverse robot datasets. Moreover, robot policies that
            follow natural language instructions are typically trained on either templated language or expensive
            human-labeled instructions, hindering their scalability. To this end, we introduce <b>NILS</b>:
            <b>N</b>atural language <b>I</b>nstruction <b>L</b>abeling for <b>S</b>calability. NILS automatically labels
            uncurated, long-horizon robot data at scale in a zero-shot manner without any human intervention. NILS
            combines pre-trained vision-language foundation models in a sophisticated, carefully considered manner in
            order to detect objects in a scene, detect object-centric changes, segment tasks from large datasets of
            unlabelled interaction data and ultimately label behavior datasets. Evaluations on BridgeV2 and a kitchen
            play dataset show that NILS is able to autonomously annotate diverse robot demonstrations of unlabeled and
            unstructured datasets, while alleviating several shortcomings of crowdsourced human annotations.
        </div>
    </div>
</div>

---

## Technical Summary
<video width="100%" controls muted loop playsinline>
    <source src="/static/video/NILS_new.mp4" type="video/mp4">
</video>

---

<!-- > Note: This is an example of a Jekyll-based project website template: [Github link](https://github.com/shunzh/project_website).\
> The following content is generated by ChatGPT. The figure is manually added. -->

## Architecture
![MDT-V Overview](./static/image/lupus-example.png)
Overview of the proposed NILS framework for labeling long-horizon robot play sequences
in a zero-shot manner using an ensemble of pretrained expert models. NILS consists of three stages:
- all relevant objects in the video are detected
- object-centric changes are detected and collected
- object change information is used to detect keystates and an LLM is prompted to generate a language label for the task




---
<h2>Examples</h2>
These Examples showcase annotations generated by our framework and the respective scene annotations. Press Play to start playing the long-horizon trajectory and sample to sample a new trajectory.
<div class="columns is-centered has-text-centered">
    <div class="column is-one-third " id="nils-video-container">
        <h4>Video</h4>
        <video id="nils-video" width="100%" muted playsinline>
            <source src="" type="video/mp4">
        </video>
    </div>
    <div class="column is-one-third ">
        <h4>Last Keystate</h4>
        <canvas id="nils-keystate" width="100%" height="100%"></canvas>
    </div>



    <div class="column is-one-third ">
        <h4>Scene Annotations</h4>

        <div class="fixed-grid">
            <div class="grid">

                <div class="cell is-col-span-1">
                    <video id="nils-video-depth" width="100%" muted playsinline>
                        <source src="" type="video/mp4">
                    </video>
                </div>
                <div class="cell is-col-span-1">
                    <video id="nils-video-boxes" width="100%" muted playsinline>
                        <source src="" type="video/mp4">
                    </video>
                </div>
                <div class="cell is-col-span-1">
                    <video id="nils-video-masks" width="100%" muted playsinline>
                        <source src="" type="video/mp4">
                    </video>
                </div>
                <div class="cell is-col-span-1">
                    <video id="nils-video-robot" width="100%" muted playsinline>
                        <source src="" type="video/mp4">
                    </video>
                </div>

            </div>
        </div>
    </div>
</div>
<div class="columns is-centered has-text-centered">
    <div class="column">
        <div class="buttons is-centered">
            <button id="nils-sample-button" class="button">Sample</button>
            <button id="nils-play-pause-button" class="button">Play/Pause</button>
            <!-- <button id="nils-prev-key-button" class="button">Previous Keystate</button>
            <button id="nils-next-key-button" class="button">Next Keystate</button> -->
        </div>
    </div>
</div>
<div class="columns is-centered has-text-centered">
    <div class="column">
        <h4>Generated Labels</h4>
        <div id="nils-labels-container"></div>
    </div>
</div>
<style>
    #nils-labels-container {
        display: flex;
        flex-direction: column;
        justify-content: space-evenly;
        align-items: center;
        gap: 1em;
    }

    #nils-keystate {
        width: 100%;
    }
</style>
<script>

    const ANNOTATION_TYPES = [
        'all_gt_ks',
        'all',
        'enable_detection_ensemblingenable_object_state_filteringenable_scene_graph_denoisingenable_detection_refinmentenable_object_centric_relations',
        'enable_temporal_aggregationenable_detection_ensemblingenable_object_state_filteringenable_scene_graph_denoisingenable_detection_refinmentenable_object_centric_relationssimple_initial_object_detection',
        'enable_temporal_aggregationenable_object_state_filteringenable_scene_graph_denoisingenable_object_centric_relations',
        'gemini_pro',
        'gpt4v',
        'object_movement_gripper_close_scene_graph_object_state'
    ]

    async function loadPaths() {
        const response = await fetch('./static/bridge_vis/paths.txt')
        const data = await response.text()
        const paths = data.split('\n')
        return paths
    }

    async function loadAnnotationsAndVideoLinkFromPath(path) {
        const responses = ANNOTATION_TYPES.map((type) =>
            fetch(`./static/bridge_vis/${path}/${type}.txt`)
                .then(response => {
                    if (response.ok) {
                        return response.text()
                    }
                    return false
                })
                .catch(err => false)
        )

        const annotations_list = (await Promise.all(responses))
            .map((response, index) => response ? [ANNOTATION_TYPES[index], processAnnotation(response)] : null)
            .filter(item => item)
        const annotations = Object.fromEntries(annotations_list)

        const videoLink = `./static/bridge_vis/${path}/orig_conv.mp4`

        const base_path = `./static/bridge_vis/${path}/`

        return { annotations, videoLink, base_path }
    }

    function processAnnotation(fileContent) {
        const lines = fileContent.split('\n')
        const parsedData = lines.map(line => {
            if (line === '') {
                return null
            }
            const [_, keystate, labels] = line.match(/Keystate: (\d+) - Annotation: (\[.*\])/)
            sanitized = labels // I hate this, why can't it be proper JSON, why are we using python print output uggh
            .replace(/\['/g, '["')
            .replace(/'\]/g, '"]')
            .replace(/', '/g, '", "')
            .replace(/", '/g, '", "')
            .replace(/', "/g, '", "')
            try {
                return {
                    keystate: parseInt(keystate),
                    labels: JSON.parse(sanitized)
                }
            } catch (e) {
                console.error(keystate, labels, sanitized, e)
                throw e
            }
        }).filter(item => item)
        return parsedData
    }

    function sampleFromPaths(paths) {
        const randomIndex = Math.floor(Math.random() * paths.length)
        return paths[randomIndex]
        // return paths[0]
    }

    const state = {
        annotations: null,
        selected_annotation_type: 'all_gt_ks',
        current_frame: 0,
        keystate: null,
        prev_keystate: null,
        fps: null,
        video_loaded: false
    }

    window.state = state

    function resetState() {
        state.annotations = null
        state.current_frame = 0
        state.keystate = null
        state.prev_keystate = null
    }

    function updateUI() {
        if (!state.video_loaded) {
            return
        }

        const shouldUpdate = updateKeystate()
        if (shouldUpdate) {
            fillLabels()
            fillCanvas()
        }
    }

    function updateKeystate() {
        const annotations = state.annotations[state.selected_annotation_type]
        const keystates = annotations.map(label => label.keystate)
        const newKeystate = keystates.find(keystate => state.current_frame <= keystate) // array is short, so binary search not needed
        console.log(state.current_frame, newKeystate)
        if (newKeystate !== state.keystate) {
            state.prev_keystate = state.keystate
            state.keystate = newKeystate
            return true
        }
        return false
    }

    function fillLabels() {
        const labels = state.annotations[state.selected_annotation_type].find(label => label.keystate === state.keystate).labels
        const labelsContainer = $('#nils-labels-container')
        labelsContainer.empty()
        labels.forEach(label => {
            const labelElement = $('<div></div>').text(label)
            labelsContainer.append(labelElement)
        })
    }

    function fillCanvas() {
        const video = $('#nils-video')[0]
        const canvas = $('#nils-keystate')[0]
        const ctx = canvas.getContext('2d')
        ctx.drawImage(video, 0, 0, video.videoWidth, video.videoHeight, 0, 0, video.videoWidth, video.videoHeight)
    }

    $(document).ready(async function () {
        const paths = await loadPaths()

        async function sample() {
            resetState()
            const path = sampleFromPaths(paths)
            const { annotations, videoLink, base_path } = await loadAnnotationsAndVideoLinkFromPath(path)

            const depth_link = base_path + 'annotated_frames/depth/depth_conv.mp4'
            const boxes_link = base_path + 'annotated_frames/annotated_conv.mp4'
            const masks_link = base_path + 'masks.mp4'
            const robot_link = base_path + 'annotated_frames/robot/robot_conv.mp4'
            //const masks_link = depth_link




            state.annotations = annotations
            $('#nils-video source').attr('src', videoLink)

            $('#nils-video-depth source').attr('src', depth_link)
            $('#nils-video-boxes source').attr('src', boxes_link)
            $('#nils-video-masks source').attr('src', masks_link)
            $('#nils-video-robot source').attr('src', robot_link)

            $('#nils-video')[0].load()
            $('#nils-video-depth')[0].load()
            $('#nils-video-boxes')[0].load()
            $('#nils-video-masks')[0].load()
            $('#nils-video-robot')[0].load()

            updateUI()
        }

        await sample()

        $("#nils-sample-button").click(async function () {
            await sample()
        })

        $("#nils-play-pause-button").click(function () {
            if (!state.video_loaded) {
                return
            }

            const video = $('#nils-video')[0]

            const video_depth = $('#nils-video-depth')[0]
            const video_boxes = $('#nils-video-boxes')[0]
            const video_masks = $('#nils-video-masks')[0]
            const video_robot = $('#nils-video-robot')[0]


            if (video.paused) {
                video.play()
                video_depth.play()
                video_boxes.play()
                video_masks.play()
                video_robot.play()

            } else {
                video.pause()
                video_depth.pause()
                video_boxes.pause()
                video_masks.pause()
                video_robot.pause()

            }
        })

        // $("#nils-prev-key-button").click(function() {
        //     if (!state.video_loaded) {
        //         return
        //     }
        //     const annotations = state.annotations[state.selected_annotation_type]
        //     const keystates = annotations.map(label => label.keystate)
        //     const currentIndex = keystates.indexOf(state.keystate)
        //     if (currentIndex > 0) {
        //         state.current_frame = keystates[currentIndex - 1]
        //         $('#nils-video')[0].currentTime = state.current_frame / state.fps
        //         updateUI()
        //     }
        // })

        // $("#nils-next-key-button").click(function() {
        //     if (!state.video_loaded) {
        //         return
        //     }
        //     const annotations = state.annotations[state.selected_annotation_type]
        //     const keystates = annotations.map(label => label.keystate)
        //     const currentIndex = keystates.indexOf(state.keystate)
        //     if (currentIndex < keystates.length) {
        //         state.current_frame = keystates[currentIndex]
        //         $('#nils-video')[0].currentTime = state.current_frame / state.fps
        //         updateUI()
        //     }
        // })

        $('#nils-video').on('timeupdate', function () {
            state.current_frame = Math.floor(this.currentTime * state.fps)
            updateUI()
        })

        $('#nils-video').on('loadeddata', function () {
            const video = $('#nils-video')[0]
            const canvas = $('#nils-keystate')[0]
            const videoWidth = video.videoWidth
            const videoHeight = video.videoHeight
            canvas.width = videoWidth
            canvas.height = videoHeight

            state.fps = state.annotations[state.selected_annotation_type].slice(-1)[0].keystate / video.duration
            state.video_loaded = true
        });
    })


</script>
---
## Example Labeling Videos

These videos showcase the annotations generated by NILS on BridgeV2 and Fractal. The bounding boxes are the boxes obtained after Stage 2 and NILS' filtering steps.

<!--Bounding boxes are generated using GroundingDINO with object descriptions generated by querying a VLM for names. The queried names and the bounding boxes are used to select consistent and representative object names across frames by leveraging *temporal consensus*, *co-occurrence* and *object detection alignment*. They are also used to compute object movement and relations, which, alongside other signals such as end-effector position, gripper state and timestamp, are used to detect keystates and create a set of templated language observations. Using these, NILS then generates natural language descriptions of the task by querying an LLM with suitable prompt.-->
<div class="columns is-centered has-text-centered">
    <div class="column columns is-four-fifths is-centered has-text-centered">
        <div class="column is-centered">
            <iframe style="width: 100%; aspect-ratio: 16 / 9;" src="https://www.youtube-nocookie.com/embed/o22Y-kc8gEk" title="YouTube video player" frameborder="0" allow="autoplay; clipboard-write; encrypted-media; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
            <p>Annotations for Bridge V2</p>
        </div>
        <div class="column is-centered">
            <iframe style="width: 100%; aspect-ratio: 16 / 9;" src="https://www.youtube-nocookie.com/embed/cqGS5_mlJLw" title="YouTube video player" frameborder="0" allow="autoplay; clipboard-write; encrypted-media; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
            <p>Annotations for Fractal 2022</p>
        </div>
    </div>
</div>

---
<h2>Policy Rollouts</h2>
These examples showcase some tasks performed by a policy trained on our real-kitchen dataset that is annotated by NILS. The policy is evaluated on the same toy kitchen.

<div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths is-centered">
        <div class="columns is-centered">
            <div class="column">
                <video autoplay muted loop playsinline>
                    <source src="/static/video/real_rollout/Archive/banana_in_sink.mp4" type="video/mp4">
                </video>
            </div>
            <div class="column">
                <video autoplay muted loop playsinline>
                    <source src="/static/video/real_rollout/Archive/fridge_fail.mp4" type="video/mp4">
                </video>
            </div>
            <div class="column">
                <video autoplay muted loop playsinline>
                    <source src="/static/video/real_rollout/Archive/microwave_door.mp4" type="video/mp4">
                </video>
            </div>
        </div>
        <div class="columns" is-centered>
            <div class="column">
                <video autoplay muted loop playsinline>
                    <source src="/static/video/real_rollout/Archive/open_microwave.mp4" type="video/mp4">
                </video>
            </div>
            <div class="column">
                <video autoplay muted loop playsinline>
                    <source src="/static/video/real_rollout/Archive/open_oven_fail.mp4" type="video/mp4">
                </video>
            </div>
            <div class="column">
                <video autoplay muted loop playsinline>
                    <source src="/static/video/real_rollout/Archive/pot_to_the_rigth_2.mp4" type="video/mp4">
                </video>
            </div>
        </div>
        <div class="columns" is-centered>
            <div class="column">
                <video autoplay muted loop playsinline>
                    <source src="/static/video/real_rollout/Archive/oven_fridge_fail.mp4" type="video/mp4">
                </video>
            </div>
            <div class="column">
                <video autoplay muted loop playsinline>
                    <source src="/static/video/real_rollout/Archive/pot_in_sink_2.mp4" type="video/mp4">
                </video>
            </div>
            <div class="column">
                <video autoplay muted loop playsinline>
                    <source src="/static/video/real_rollout/Archive/pot_in_sink.mp4" type="video/mp4">
                </video>
            </div>
        </div>
    </div>
</div>

Following examples are rollouts of an Octo policy trained on the BridgeV2 dataset using the labels generated by NILS. Both real-world and simulation (using SimplerEnv) rollouts were performed.

<div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths is-centered">
        <div class="columns is-centered">
            <div class="column">
                <video autoplay muted loop playsinline>
                    <source src="/static/video/bridge/ra.mp4" type="video/mp4">
                </video>
                <p>Place the green spoon on top of the rag</p>
            </div>
            <div class="column">
                <video autoplay muted loop playsinline>
                    <source src="/static/video/bridge/rb.mp4" type="video/mp4">
                </video>
                <p>Place the green spoon on top of the rag</p>
            </div>
        </div>
        <div class="columns is-centered">
            <div class="column">
                <video autoplay muted loop playsinline>
                    <source src="/static/video/bridge/rc.mp4" type="video/mp4">
                </video>
                <p>Place the sushi inside the wooden bowl</p>
            </div>
            <div class="column">
                <video autoplay muted loop playsinline>
                    <source src="/static/video/bridge/rd.mp4" type="video/mp4">
                </video>
                <p>Place the sushi inside the green bowl</p>
            </div>
        </div>
        <div class="columns is-centered">
            <div class="column">
                <video autoplay muted loop playsinline>
                    <source src="/static/video/bridge/sa.mp4" type="video/mp4">
                </video>
                <p>Place the yellow spoon on top the blue cloth</p>
            </div>
            <div class="column">
                <video autoplay muted loop playsinline>
                    <source src="/static/video/bridge/sb.mp4" type="video/mp4">
                </video>
                <p>Relocate the yellow spoon from the table to inside the blue cloth</p>
            </div>
        </div>
    </div>
</div>

---
<h2>Failure Cases</h2>
<div class="columns is-centered has-text-centered">
    <div class="column">
        <div class="fixed-grid">
            <div class="grid is-size-7">
                <div class="cell is-col-span-1">
                    <div class="columns is-centered has-text-centered is-vcentered">
                        <div class="column is-half is-vcentered">

                            <img src="./static/bridge_vis/datacol1_toykitchen1_many_skills_0/split/1.gif.gif"
                                width="100%">
                        </div>
                        <div class="column is-half">

                            Move the <span style="color: #ff0000">fork</span> forward <br>
                            Move the <span style="color: #ff0000">fork</span> to the left <br>
                            Move the <span style="color: #ff0000">fork</span> away from the round object <br>
                            Move the <span style="color: #ff0000">fork</span> to the left
                        </div>
                    </div>

                </div>
                <div class="cell is-col-span-1">
                    <div class="columns is-centered has-text-centered is-vcentered">
                        <div class="column is-half is-vcentered">

                            <img src="./static/bridge_vis/datacol1_toykitchen6_pnp_sweep_00/split/18.gif.gif"
                                width="100%">
                        </div>
                        <div class="column is-half">
                            Move the pan to the <span style="color: #ff0000">left</span> of the stovetop <br>
                            Clean the pan with the kitchen towel <br>
                            Place the pan on top of the kitchen towel, next to the chicken wing and spoon <br>
                            Move the pan 29.5 pixels to the left and 79.5 pixels forward
                        </div>
                    </div>

                </div>
                <div class="cell is-col-span-1">
                    <div class="columns is-centered has-text-centered is-vcentered">
                        <div class="column is-half is-vcentered">

                            <img src="./static/bridge_vis/datacol2_folding_table_fold_cloth_pnp_01/split/4.gif.gif"
                                width="100%">
                        </div>
                        <div class="column is-half">

                            <span style="color: #ff0000">Wipe the table </span><br>
                            <span style="color: #ff0000">Dust the lamp </span><br>
                            <span style="color: #ff0000">Polish the silverware </span><br>
                            <span style="color: #ff0000">Wipe up the spill </span><br>
                        </div>
                    </div>

                </div>
                <div class="cell is-col-span-1">
                    <div class="columns is-centered has-text-centered is-vcentered">
                        <div class="column is-half is-vcentered">

                            <img src="./static/bridge_vis/datacol2_folding_table_pnp_push_sweep_00/split/2.gif.gif"
                                width="100%">
                        </div>
                        <div class="column is-half">

                            Move the toy corn to the left of the blue cup<br>
                            Place the toy corn in the center of the table, <span style="color: #ff0000">next to the blue
                                cup</span><br>
                            Shift the toy corn 130.5 pixels to the right<br>
                            Relocate the toy corn from the left side of the table to the center
                        </div>
                    </div>

                </div>
                <div class="cell is-col-span-1">
                    <div class="columns is-centered has-text-centered is-vcentered">
                        <div class="column is-half is-vcentered">

                            <img src="./static/bridge_vis/datacol2_laundry_machine_pnp_push_sweep_00/split/2.gif.gif"
                                width="100%">
                        </div>
                        <div class="column is-half">
                            Move the soda can to the right and place it <span style="color: #ff0000">next to the toy mouse</span> <br>
                            Pick up the soda can and place it to the  <span style="color: #ff0000">left of the toy mouse </span> <br>
                            Relocate the soda can from its initial position to the <span style="color: #ff0000">left of the toy mouse </span><br>
                            Place the soda can <span style="color: #ff0000">next to the toy mouse on its left side</span>
                        </div>
                    </div>

                </div>
                <div class="cell is-col-span-1">
                    <div class="columns is-centered has-text-centered is-vcentered">
                        <div class="column is-half is-vcentered">

                            <img src="./static/bridge_vis/datacol2_tabletop_dark_wood_many_skills_00/split/7.gif.gif"
                                width="100%">
                        </div>
                        <div class="column is-half">

                            Remove the pot lid from the <span style="color: #ff0000"> sausage toy </span> <br>
                            Lift the pot lid off the <span style="color: #ff0000"> sausage toy </span> <br>
                            Take the pot lid off the <span style="color: #ff0000"> sausage toy </span> <br>
                            Uncover the <span style="color: #ff0000"> sausage toy </span> by removing the pot lid <br>
                        </div>
                    </div>

                </div>
            </div>
        </div>
    </div>
</div>


<!-- <div class="column">
<video  autoplay muted loop playsinline>
    <source src="/static/video/real_rollout/Archive/pot_to_the_right.mp4" type="video/mp4">
</video>
</div> -->
